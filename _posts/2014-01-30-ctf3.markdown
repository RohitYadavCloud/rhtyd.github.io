---
layout: post
title: CTF3 Experience
excerpt: Capture The Flag III
---

Unlike last CTFs by Stripe, this year's CTF was
[announced](https://stripe.com/blog/ctf3-coming-soon) to be around [distributed
systems](https://stripe.com/blog/ctf3-launch).  This sounded fun so I
[participated](https://stripe-ctf.com/achievements/bhaisaab) in CTF3. I was able
to get to the final level all by myself which was fun, in this post I'll try to
share my experience. I've pushed my [code on
github](https://github.com/bhaisaab/hacklab/tree/master/ctf3).

<br><p align="center"><a href="/images/ctf3.png"><img align="center" src="/images/ctf3.png"></a></p><br>

Level0 was _fizzbuzz_ problem which was fun to implement. The stub implementation
was in Ruby but to clear this level I wrote a solution in C++. The problem was
to highlight or add markups `<>` to all words of a given file which are in a
provided dictionary file. The optimal solution would consume O(n) which many
people implemented.

Level1 was interesting problem around digital currencies such as bitcoins.
Because of this problem I finally understood various concepts such as
distributed ledger, proof of work, block chains etc. The problem was to create a
commit by giving yourself one gitcoin (in a LEDGER.txt file) and committing it
in such a way that the commit SHA would be less than provided difficulty. The
logic was to compute SHA1 of a static string with varying nonce (or counters)
which concluded the proof of work. I was able to pull it off in a Python based
miner and again by a more efficient and fast Go based miner. People use CUDA and
GPU based implementations which helped them have an edge in the round-matches.

Level2 was interesting problem around DDOS where we were to stop an ongoing DDOS
attack by rate limiting API calls and letting legitimate API calls pass on to
backend server. Using rate limiting algorithm this was fairly simple to implement
and qualify. While I would love to know how the winners of this level implemented
their solution, I did not invest a lot of time on it. It was fun to write
javascript on the server side for me since it's actually the first time I've
ever written javascript that did something :) I also like the testing framework
which was used to simulate the network and do the scoring.

Level3 was serious problem of distributed information retrieval which we were
supposed to implement in Scala. Scala itself was difficult to work with,
nonetheless my naive implementation used the algorithm to shard the file walk
travesal and read files and create reverse indexes of words on a give file's
line number. Using this multimap and map of filenames, for a given query I was
able to reply which files by line number contained a word that matched given
query. While I was able to qualify this level, I invested a lot of time (the
entire weekend) on trying to come up with a competant solution (which I could n't).
The JVM gave me more problems than my own algorithms. I would probably invest
sometime in understand some theory and learn from other people's solutions.

Level4 was most challenging. The problem was to implement a distributed
highly available mysql server. While sqlite was used as db data store, like a
lot of folks I used goraft for consensus since I [found some
hints](https://github.com/goraft/raft/pull/146) and the Go stub code looked a lot
like raftd which is an example implementation for using raft library. I really liked
the Octopus simulator which could simulate flaky network and the use of unix sockets.
This was a nice hack, whoever architected this problem must be really awesome, kudos!
I spent the whole night to come up with an optimized solution but I failed to do it
in time. So, I'll explore competant solutions as soon as champions start posting
their solutions. And perhaps study Raft and Paxos papers.

Overall my experience was good, I liked the competition and the problems. It was
also an opportunity to learn new things and identify scopes of improvement in one's
skills.

Thanks to the fine folks at Stripe, [gdb](https://twitter.com/thegdb) et al
for this awesome CTF. Hopefully in the next CTF their server infrastructure would
be more scalable to handle loads and the problem would be much clearer with better
READMEs and state any data/filepath assumptions (like data and listening paths in level4).
